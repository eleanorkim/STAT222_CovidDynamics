---
title: "Spatial Dynamics - Modeling"
subtitle: "Aarushi Somani, Eleanor Kim, Lauren Murai, Meichen Chen"
output:
  pdf_document: default
  html_document: default
date: '2024-03-11'
editor_options: 
  markdown: 
    wrap: 72
---

```{r, warning = FALSE}
#load packages
library(sandwich)
library(lmtest)
library(dplyr)
library(tibble)
library(stargazer)
library(car)
```

# Read in 7 Datasets

## All county data + Urban county data with Wave dummies

```{r}
# Weekly Spatial Metrics with Time Wave Columns
all_weekly_spatial_metrics_waves = read.csv("weekly_spatial_metrics_waves.csv")

# same data set but calculations from urban counties only (pop >250k)
urban_weekly_spatial_metrics_waves = read.csv("urban_weekly_spatial_metrics_waves.csv")
```

Output: weekly_spatial_metrics_waves - Weekly data set with
corresponding covid cases, spatial correlations, and correlation
lengths - 157 rows (weeks 9 - 165) x 57 columns (date, cases, cor
length, C(r), wave dummies) - features: start date of week, total cases,
marginal cases, next week's marginal cases, C(r) for distance intervals
from [0,50] to [970,1000], correlation length, wave, wave 1 dummy, wave
2 dummy

## All county data + Urban county data with Region + Wave dummies
```{r}
# Weekly Spatial Metrics with Region Columns
all_regional_weekly_spatial_metrics = read.csv("regional_weekly_spatial_metrics.csv")

# same data set but calculations from urban counties only (pop >250k)
urban_regional_weekly_spatial_metrics = read.csv("urban_regional_weekly_spatial_metrics.csv")
```

Output: regional_weekly_spatial_metrics - Weekly data set with
corresponding covid cases, spatial correlations, and correlation
lengths - 628 rows (weeks 9 - 165 x 4 regions) x 59 columns (date,
cases, cor length, C(r), region dummies) - features: start date of week,
total cases, marginal cases, next week's marginal cases, C(r) for
distance intervals from [0,50] to [970,1000], correlation length,
region, northeast dummy, midwest dummy, south dummy

## All county data + Urban county data with MHHINC + Wave dummies

```{r}
# Weekly Spatial Metrics with Median Household Income Columns
all_mhhinc_weekly_spatial_metrics = read.csv("mhhinc_weekly_spatial_metrics.csv")

# same data set but calculations from urban counties only (pop >250k)
urban_mhhinc_weekly_spatial_metrics = read.csv("urban_mhhinc_weekly_spatial_metrics.csv")
```

Output: mhhinc_weekly_spatial_metrics - Weekly data set with
corresponding covid cases, spatial correlations, and correlation
lengths - 1570 rows (weeks 9 - 165 x 10 combinations of 4 tiers) x 71
columns (date, cases, cor length, C(r), poverty dummies) - features:
start date of week, total cases, marginal cases, next week's marginal
cases, C(r) for distance intervals from [0,50] to [970,1000],
correlation length, income pair tiers (4 choose 2) dummies, income tier
differences (same tier, difference of 1, difference of 2, difference of
3)

## All county data with Region + MHHINC + Wave dummies

```{r}
# Weekly Spatial Metrics with Region and Median Household Income Columns
all_region_mhhinc_weekly_spatial_metrics = read.csv("region_mhhinc_weekly_spatial_metrics.csv")

# Local Corelation with Region + MHHINC Columns
all_region_mhhinc_weekly_localcor = read.csv("region_mhhinc_weekly_localcor.csv")
urban_region_mhhinc_weekly_localcor = read.csv("urban_region_mhhinc_weekly_localcor.csv")
```

Output: region_mhhinc_weekly_spatial_metrics - Weekly data set with
corresponding covid cases, spatial correlations, and correlation
lengths - 6280 rows (weeks 9 - 165 x 10 combinations of 4 tiers X 4
regions) x 67 columns (date, cases, cor length, C(r), region and tier
difference dummies) - features: start date of week, total cases,
marginal cases, next week's marginal cases, C(r) for distance intervals
from [0,50] to [970,1000], correlation length, region dummies, tier
difference (same,1,2,3) dummies

# Simple Model, No Dummies (2 data sets, 4 models, 2 table, 2 models/table)

## Prepare Model Combinations

```{r}
# Data sets: (1) all counties & (2) urban counties
datasets = list(all_weekly_spatial_metrics_waves, urban_weekly_spatial_metrics_waves)
df_names = c("all","urban")

# Predictor: (1) correlation length & (2) log(local correlation)
predictor = c("cor_lengths", "r_0_50")
pred_names = c("corlength","localcor")
```

## Generate Models

```{r, warning = FALSE}
# Create an empty list to store the models
simple_lm_models <- list()

# Iterate of every combination of data, predictor, and covariates
for (d in 1:length(datasets)) {
  df = datasets[d][[1]]
  for (p in 1:length(predictor)) {
     
      # Create the formula
      lm_formula <- as.formula(paste("log(next_week_marginal_cases) ~", predictor[p]))
      
      # Fit the linear model
      lm_model <- lm(lm_formula, data = df)
      
      # Generate a name for the model object
      model_name <- paste(df_names[d],"_", pred_names[p], sep = "")
      
      # Save the model to the list
      simple_lm_models[[model_name]] <- lm_model
  }}
names(simple_lm_models)
```

## View Model Summaries

```{r}
for (m in 1:length(simple_lm_models)){
  print(summary(simple_lm_models[[m]]))
}
```


```{r, warning = FALSE}
# stargazer table for all_corlengths_region and urban_corlengths_region
# (1) is all
# (2) is urban
stargazer(
  c(simple_lm_models[1], simple_lm_models[3]),
  type = 'text', 
  title = "Regression of Covid Cases on Correlation Length"
)
```

```{r, warning = FALSE}
# all_localcor_wave_region and urban_localcor_wave_region
# (1) is all
# (2) is urban
stargazer(
  c(simple_lm_models[2], simple_lm_models[4]),
  type = 'text', 
  title = "Regression of Covid Cases on Local Correlation"
)
```

## Check conditions of Normality of Residuals, Homoskedasticity, Linearity, Independence of Residuals

```{r}
for (i in 1:length(simple_lm_models)) {
lm_model = simple_lm_models[[i]]

# 1. Linearity Check (Visual Inspection)
plot(residuals(lm_model) ~ fitted(lm_model))

# 2. Independence Check# Durbin-Watson test
durbinWatsonTest(lm_model)

# 3. Homoscedasticity Check (Visual Inspection)
# Breusch-Pagan test for Heteroscedasticity
bptest(lm_model)

# 4. Normality of Residuals Check
# Histogram of residuals
hist(residuals(lm_model), main = "Histogram of Residuals")
}

# Heteroskedasticity/Non-linearity in Urban Local Correlation Model
```

## Print Results

```{r}
units = c(round(sd(urban_weekly_spatial_metrics_waves$cor_lengths, na.rm = TRUE),2), round( sd(urban_weekly_spatial_metrics_waves$r_0_50) ,2))
var = c("correlation length","local correlation")
for (i in 1:4) {
  adj_i = 2-i%%2
  print(paste("a 1 sd increase in ", var[adj_i]," (",units[adj_i], ") corresponds to a ", round(simple_lm_models[[i]]$coefficients[2]*units[adj_i]*100,2),"% change in cases in the following week across ", df_names[(i>2)+1]," counties", sep=""))}
```
Effects are less strong when comparing across only the urban counties. Local correlation and correlation length seem to both hold a strong effect in indicating/predicting a rise in cases in the next week.

# Eleanor: Region + Median Household Income Models (1 data set, 2 models, 1 table, 1 model/table)

## Prepare Model Combinations

```{r}
# Data sets: (1) all counties & (2) urban counties
datasets = list(all_region_mhhinc_weekly_localcor, urban_region_mhhinc_weekly_localcor)
df_names = c("all_","urban_")

# Predictor: (1) correlation length & (2) local correlation
predictor = c("r_0_50")
pred_names = c("localcor")

# Covariates (1) region + mhhinc & (2) region + mhhinc + wave
covariates = list(c("*factor(region)*same_tier","*factor(region)*tier_diff_1","*factor(region)*tier_diff_2"))
var_names = c("region_mhhinc")
```

## Generate Models

```{r}
# Create an empty list to store the models
lm_models <- list()

# Iterate over every combination of data, predictor, and covariates
for (d in 1:length(datasets)) {
  df = datasets[d][[1]]
for (p in 1:length(predictor)) {
  for (c in 1:length(covariates)) {
    interactions = c()
    for (i in 1:length(covariates[[c]])) {
      interactions[i] <- paste(predictor[p], covariates[[c]][i]) }
    
    # Create the formula & fit linear model
    lm_formula <- as.formula(paste("log(next_week_marginal_cases) ~", paste(unlist(interactions), collapse = " + ")))
    lm_model <- lm(lm_formula, data = df)
    
    # Name model and save to list
    model_name <- paste(df_names[d], pred_names[p], "_", var_names[c], sep = "")
    lm_models[[model_name]] <- lm_model}}}

names(lm_models)
```


## View Model Summaries

```{r}
for (m in 1:length(lm_models)){
  print(summary(lm_models[[m]]))
}
```

```{r}
# Correlation Length Models
stargazer(
  lm_models,
  type = 'text'
)
```

## Check conditions of Normality of Residuals, Homoskedasticity,Linearity , No Perfect Multicollinearity, Independence of Residuals

```{r}
for (i in 1:length(lm_models)) {
lm_model = lm_models[[i]]

# 1. Linearity Check (Visual Inspection)
plot(residuals(lm_model) ~ fitted(lm_model))

# 2. Independence Check
# Durbin-Watson test
print(durbinWatsonTest(lm_model)[3])


# 3. Homoscedasticity Check
# Breusch-Pagan test for Heteroscedasticity
print(bptest(lm_model)$p.value)

# 4. Normality of Residuals Check (Visual Inspection)
hist(residuals(lm_model), main = "Histogram of Residuals")
}
# 5. No Perfect Multicollinearity Check
# Variance Inflation Factors (VIF)
vif(lm(log(next_week_marginal_cases) ~  r_0_50 + factor(region) + factor(mhhinc_tiers) , data = all_region_mhhinc_weekly_localcor))

# Heteroskedasticity in the urban model --> use robust standard errors
```



## Functions to print significant results

```{r}
# Create function that prints interpretation of coefficients

print_interpretation <- function(coef, wave_val = "every wave",region_val = "whole US", tier_descr_val = "are disregarded", significant=TRUE, pred = "r_0_50", county="all counties", df=weekly_spatial_metrics_waves) {
  if (!is.na(coef) && isTRUE(significant)) {
    
    # Prep the data frame to calculate appropriate sd
    if (wave_val !="every wave") {
    df = filter(df, wave == as.numeric(gsub("\\D", "", wave_val))) }
    if (region_val !="whole US") {
    df = filter(df, region == region_val)}
    if (tier_descr_val != "are disregarded") {
    df = filter(df, tier_descr == tier_descr_val)}

    # Calculate sd units
    if (pred == "cor_lengths") {
      factor_value = round(sd(df$cor_lengths, na.rm = TRUE),2)
      pred_type = paste("correlation length (",factor_value ," km)",sep="")
    } else {
      factor_value = round(sd(df$r_0_50, na.rm = TRUE),2)
      pred_type = paste("local correlation (",factor_value,")",sep="")
    }
    
    # To Print
    cat("- For", county,"across", wave_val, "in the", region_val, "where the median household income tiers", tier_descr_val, "\n")
    cat("a 1 sd increase in ", pred_type," corresponds to a ", 
        round(coef * factor_value * 100, 2), "% increase in cases in the following week. Significant? ", significant, "\n", sep = "")
  }
}

# Create function that returns coefficient
save_coefficient <- function(interaction) {
  if (!is.na(interaction)) {
    coef <- interaction + coefficients[2]
    return(coef)
  } else {
    return(NA)
  }
}

# Create function to calculate significance of coefficient based on t-statistic
is_significant <- function(coef, se, threshold = 2.576) {
  if (!is.na(coef) && !is.na(se)) {
    # Calculate t-statistic
    t_stat <- coef / se
    # Check if absolute value of t-statistic exceeds threshold for significance
    return(t_stat > threshold) # for 99% confidence 
  } else {
    return(FALSE)  # Treat missing values as not significant
  }
}
```

## Print non-NA Significant Results

```{r}
# Iterate over Regions and Tier diff dummies
for (x in 1:length(lm_models)) {
  lm_model <- lm_models[[x]]
  
  if (x == 1) {
    county <- "all counties"
    df = all_region_mhhinc_weekly_localcor
  } else {
    county <- "urban counties"
    df = urban_region_mhhinc_weekly_localcor
  }
  
  # Get stats
  coefficients <- coef(lm_model)
  coef_names <- names(coef(lm_model))
  se <- sqrt(diag(vcovHC(lm_model)))
  se_named <- rep(NA, length(coef_names))
  se_named[names(se)] <- se
  st_errors <- se_named[coef_names]
  
  # Initialize values
  regions <- c("Northeast", "South", "West", "Midwest")
  tier_diff <- c("same_tier", "tier_diff_1", "tier_diff_2", "tier_diff_3")
  tier_descr <- c("are the same", "differ by 1", "differ by 2", "differ by 3")
  full_coef <- c()
  significant <- c()
  i <- 1
  
  # Iterate over Regions and Tier diff dummies
  for (r in 1:length(regions)) {
    region <- regions[r]
    for (m in 1:length(tier_diff)) {
      tierdiff <- tier_diff[m]
      if (region == "Midwest") {
        partial_interaction_r <- 0
        se_partial_r <- 0
      } else {
        partial_interaction_r <- coefficients[(8 + r)]
        se_partial_r <- st_errors[(8 + r)]
      }
      if (tierdiff == "tier_diff_3") {
        partial_interaction_m <- 0
        se_partial_m <- 0
      } else {
        partial_interaction_m <- coefficients[(4*(m+2))]
        se_partial_m <- st_errors[(4*(m+2))]
      } 
      if (tierdiff != "tier_diff_3" & region != "Midwest") {
        full_interaction_rm <- coefficients[paste0("r_0_50:factor(region)", region, ":", tierdiff)]
        se_full_rm <- st_errors[paste0("r_0_50:factor(region)", region, ":", tierdiff)]
      } else {
        full_interaction_rm <- 0
        se_full_rm <- 0
      }
      
      # Calculate total standard error
      se_total <- sqrt(se_partial_r^2 + se_partial_m^2 + se_full_rm^2 + st_errors[2]^2)
      
      # Store coefficient information
      interaction <- partial_interaction_r + partial_interaction_m + full_interaction_rm
      full_coef[i] <- save_coefficient(interaction) 
      
      # Print interpretation and significance
      significant[i] <- is_significant(as.numeric(full_coef[i]), as.numeric((se_total)))
      print_interpretation(full_coef[i], wave= "every wave",region, tier_descr[m], significant[i], pred = "local_cor", county, df)
      i <- i + 1
    }
  }
}
```

Regional and equality level effects are significant in the South and Midwest across every wave. Slightly stronger effects in the South than the midwest among counties of similar median household income tier. Effects are not as discernible among Urban counties. We don't have enough data to calculate correlation length but local correlation is an effective metric here.

# Lauren: Wave Models (2 data sets, 4 models, 2 tables, 2 models/table)

## Prepare Model Combinations
```{r}
# Data sets: (1) all counties & (2) urban counties
datasets = list(all_weekly_spatial_metrics_waves, urban_weekly_spatial_metrics_waves)
df_names = c("all","urban")

# Predictor: (1) correlation length & (2) log(local correlation)
predictor = c("cor_lengths", "r_0_50")
pred_names = c("corlength","localcor")
```

## Generate Models
```{r}
wave_lm_models <- list()

for (d in 1:length(datasets)) {
  df = datasets[[d]]
  for (p in 1:length(predictor)) {
    # Create the formula by including wave_1 and wave_2 as covariates
    lm_formula <- as.formula(paste("log(next_week_marginal_cases) ~", predictor[p], "+ factor(wave)"))
    #lm_formula <- as.formula(paste("log(next_week_marginal_cases) ~", predictor[p], "+ wave_1 + wave_2"))
    
    # Fit the linear model
    lm_model <- lm(lm_formula, data = df)
    
    # Generate a name for the model object
    model_name <- paste(df_names[d], "_", pred_names[p], "_waves", sep = "")
    
    # Save the model to the list
    wave_lm_models[[model_name]] <- lm_model
  }
}
names(wave_lm_models)
```

## View Model Summaries
```{r}
for (m in 1:length(wave_lm_models)) {
  print(summary(wave_lm_models[[m]]))
}
```

```{r, warning = FALSE}
# stargazer table for all_corlengths_region and urban_corlengths_region
# (1) is all
# (2) is urban
stargazer(
  c(wave_lm_models[1], wave_lm_models[3]),
  type = "text", 
  title = "Regression of Covid Cases on Correlation Length with Waves"
)
```

```{r, warning = FALSE}
# all_localcor_wave_region and urban_localcor_wave_region
# (1) is all
# (2) is urban
stargazer(
  c(wave_lm_models[2], wave_lm_models[4]),
  type = 'text', 
  title = "Regression of Covid Cases on Local Correlation with Waves"
)
```

```{r}
units = c(round(sd(urban_weekly_spatial_metrics_waves$cor_lengths, na.rm = TRUE),2), round( sd(urban_weekly_spatial_metrics_waves$r_0_50) ,2))
var = c("correlation length","local correlation")
for (i in 1:4) {
  adj_i = 2-i%%2
  print(paste("a 1 sd increase in ", var[adj_i]," (",units[adj_i], ") corresponds to a ", round(wave_lm_models[[i]]$coefficients[2]*units[adj_i]*100,2),"% change in cases in the following week across ", df_names[(i>2)+1]," counties", sep=""))}
```

## Check conditions of Normality of Residuals, Homoskedasticity,Linearity , No Perfect Multicollinearity, Independence of Residuals

```{r}
for (i in 1:length(wave_lm_models)) {
  lm_model = wave_lm_models[[i]]
  
  # Linearity Check (Visual Inspection)
  plot(residuals(lm_model) ~ fitted(lm_model))
  
  # 2. Independence Check
  # Durbin-Watson test
  durbinWatsonTest(lm_model)
  
  # 3. Homoscedasticity Check (Visual Inspection)
  # Breusch-Pagan test for Heteroscedasticity
  bptest(lm_model)
  
  # 4. Normality of Residuals Check
  # Histogram of residuals
  hist(residuals(lm_model), main = "Histogram of Residuals")
}
```

## Print Significant Results
```{r}
print_significant_wave_interpretations <- function(models) {
  for (i in 1:length(models)) {
    model <- models[[i]]
    coefficients <- summary(model)$coefficients
    
    # Print significant wave coefficients at 0.05 significance level
    for (wave in 2:3) {
      coef_name <- paste("factor(wave)", wave, sep="")
      if (coef_name %in% rownames(coefficients)) {
        coef_val <- coefficients[coef_name, "Estimate"]
        p_value <- coefficients[coef_name, "Pr(>|t|)"]
        
        if (p_value < 0.05) {  
          percent_change <- round(coef_val * 100, 2)
          
          cat("- Among all", ifelse(i <= 2, "all", "urban"), "counties in wave", wave, "\n")
          cat("a 1 unit increase in wave ", wave, " corresponds to a ", 
              percent_change, "% change in cases in the following week. Significant? TRUE\n\n", sep = "")
        }
      }
    }
  }
}
print_significant_wave_interpretations(wave_lm_models)
```

# Aarushi: Region + Wave Models (2 data sets, 8 models, 4 tables, 2 models/table)

## Prepare Model Combinations

```{r}
# Data sets: (1) all counties & (2) urban counties
datasets = list(all_regional_weekly_spatial_metrics, urban_regional_weekly_spatial_metrics)
df_names = c("all","urban")

# Predictor: (1) correlation length & (2) local correlation
predictor = c("cor_lengths", "r_0_50") #unlog local cor
predictor_names = c("corlengths","localcor")

# Covariates (1) mhhinc & (2) mhhinc + wave
covariates = list(c("*factor(wave)*northeast","*factor(wave)*midwest","*factor(wave)*south"),
                  c("*northeast","*midwest","*south"))
var_names = c("wave_region","region")
```

## Generate Models

```{r, warning = FALSE}
# Create an empty list to store the models
region_lm_models <- list()

# Iterate of every combination of data, predictor, and covariates
for (d in 1:length(datasets)) {
  df = datasets[d][[1]]
  for (p in 1:length(predictor)) {
    for (c in 1:length(covariates)) {
      interactions = c()
      for (i in 1:length(covariates[[c]])) {
        interactions[i] <- paste(predictor[p], covariates[[c]][i])}
     
      # Create the formula
      lm_formula <- as.formula(paste("log(next_week_marginal_cases) ~", paste(unlist(interactions), collapse = " + ")))
      
      # Fit the linear model
      lm_model <- lm(lm_formula, data = df)
      
      # Generate a name for the model object
      model_name <- paste(df_names[d],"_", predictor_names[p], "_", var_names[c], sep = "")
      
      # Save the model to the list
      region_lm_models[[model_name]] <- lm_model
    }}}
```

```{r}
print(names(region_lm_models))
```

## View Model Summaries

```{r}
for (m in 1:length(region_lm_models)){
  print(summary(region_lm_models[[m]]))
}
```
all_localcor_region and urban_localcor_region do not have
significant interaction terms, so we will not make a stargazer table 
for this model. Will make 3 stargazer tables, for these pairs of models:
  (1) all_corlengths_wave_region and urban_corlengths_wave_region
  (2) all_corlengths_region and urban_corlengths_region
  (3) all_localcor_wave_region and urban_localcor_wave_region
  
```{r, warning = FALSE}
# stargazer table for all_corlengths_wave_region and urban_corlengths_wave_region
# (1) is all
# (2) is urban 
stargazer(
  c(region_lm_models[1], region_lm_models[5]),
  type = 'text', 
  title = "Regression of Covid Cases on Correlation Length, Wave and Region"
)
```

```{r, warning = FALSE}
# stargazer table for all_corlengths_region and urban_corlengths_region
# (1) is all
# (2) is urban
stargazer(
  c(region_lm_models[2], region_lm_models[6]),
  type = 'text', 
  title = "Regression of Covid Cases on Correlation Length and Region"
)
```

```{r, warning = FALSE}
# all_localcor_wave_region and urban_localcor_wave_region
# (1) is all
# (2) is urban
stargazer(
  c(region_lm_models[3], region_lm_models[7]),
  type = 'text', 
  title = "Regression of Covid Cases on Local Correlation, Wave and Region"
)
```

## Print Results 

Do not print results for all_localcor_region and urban_localcor_region since there's no significant interaction terms.

First look at the models corlengths_wave_region. If we look at all counties, the interaction terms for cor_lengths:factor(wave)3 and cor_lengths:northeast are significant. If we only look at urban counties, all interaction terms are significant except cor_lengths:midwest and wave 2:midwest. I'll print results for urban_corlengths_wave_region.

```{r}
# print results for significant interaction terms for urban counties
coefficients <- coef(region_lm_models[[5]])

coef_val <- coefficients["cor_lengths:factor(wave)2"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in wave 2 \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:factor(wave)3"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in wave 3 \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:northeast"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in the NorthEast region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:south"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in the South region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:factor(wave)2:northeast"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in Wave 2 in the Northeast region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:factor(wave)2:midwest"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in Wave 2 in the Midwest region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:factor(wave)2:south"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in Wave 2 in the South region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:factor(wave)3:northeast"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in Wave 3 in the Northeast region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:factor(wave)3:midwest"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in Wave 3 in the Midwest region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["cor_lengths:factor(wave)3:south"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in Wave 3 in the South region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")

```

Next look at the models corlengths_region. If we look at all counties, the interaction term for cor_lengths:midwest is significant. If we only look at urban counties, the interaction term for cor_lengths:south is significant. 

```{r}
# print results for significant interaction terms for all counties
coefficients <- coef(region_lm_models[[2]])

coef_val <- coefficients["cor_lengths:midwest"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all counties in the Midwest region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")
```

```{r}
# print results for significant interaction terms for urban counties
coefficients <- coef(region_lm_models[[6]])

coef_val <- coefficients["cor_lengths:south"]
coef <- coef_val + coefficients["cor_lengths"]
cor_length_unit <- 50
cat("- Among all urban counties in the South region \n")
cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")
```

Lastly look at the models localcor_wave_region. If we look at all counties, the interaction terms for log(r_0_50):factor(wave)3, log(r_0_50):northeast, factor(wave)2:midwest, factor(wave)3:south and log(r_0_50):factor(wave)3:south are significant. If we only look at urban counties, the interaction terms for log(r_0_50):northeast and log(r_0_50):factor(wave)3:midwest are significant. 

```{r}
# print results for significant interaction terms for all counties
coefficients <- coef(region_lm_models[[3]])

coef_val <- coefficients["log(r_0_50):factor(wave)3"]
coef <- coef_val + coefficients["log(r_0_50)"]
cat("- Among all counties in Wave 3 \n")
cat("a 10 % increase in local correlation corresponds to a ", 
        round(exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["log(r_0_50):northeast"]
coef <- coef_val + coefficients["log(r_0_50)"]
cat("- Among all counties in the Northeast region \n")
cat("a 10 % increase in local correlation corresponds to a ", 
        round(exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["log(r_0_50):factor(wave)3:south"]
coef <- coef_val + coefficients["log(r_0_50)"]
cat("- Among all counties in Wave 3 in the South region \n")
cat("a 10 % increase in local correlation corresponds to a ", 
        round(exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")
```

```{r}
# print results for significant interaction terms for urban counties
coefficients <- coef(region_lm_models[[7]])

coef_val <- coefficients["log(r_0_50):northeast"]
coef <- coef_val + coefficients["log(r_0_50)"]
cat("- Among all counties in the Northeast region \n")
cat("a 10 % increase in local correlation corresponds to a ", 
        round(exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")

coef_val <- coefficients["log(r_0_50):factor(wave)3:midwest"]
coef <- coef_val + coefficients["log(r_0_50)"]
cat("- Among all counties in Wave 3 in the Midwest region \n")
cat("a 10 % increase in local correlation corresponds to a ", 
        round(exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")
```

## new result interpretations for region + wave models

### Check conditions of Normality of Residuals, Homoskedasticity,Linearity , No Perfect Multicollinearity, Independence of Residuals

```{r}
for (lm_model in region_lm_models) {
  
# 1. Linearity Check (Visual Inspection)
plot(residuals(lm_model) ~ fitted(lm_model))

# 2. Independence Check
# Durbin-Watson test
print(durbinWatsonTest(lm_model)[3])

# 3. Homoscedasticity Check
# Breusch-Pagan test for Heteroscedasticity
print(bptest(lm_model)$p.value)

# 4. Normality of Residuals Check (Visual Inspection)
hist(residuals(lm_model), main = "Histogram of Residuals")
}

# 5. No Perfect Multicollinearity Check
# Variance Inflation Factors (VIF)
vif(lm(log(next_week_marginal_cases) ~  cor_lengths + factor(wave) + factor(region) , data = all_regional_weekly_spatial_metrics))
vif(lm(log(next_week_marginal_cases) ~  cor_lengths + factor(wave) + factor(region) , data = urban_regional_weekly_spatial_metrics))


names(region_lm_models)

# Conditions not passed:
## Heteroskedastic in all_corlengths_wave_region, all_corlengths_region, urban_corlengths_region, urban_localcor_region
## Non-linearity in urban_localcor_region
## solutions --> use robust standard errors, reject a 99% level for strong results
```

## Print non-NA Significant Results

```{r}
# FUNCTIONS DEFINED IN E's Section

# Initialize values
predictor <- c("cor_lengths","r_0_50")
waves <- c("wave 1","wave 2", "wave 3")
regions <- c("Northeast", "Midwest", "South", "West")
full_coef = c()
full_coef1 = c()
significant = c()
significant1 = c()
i=1
j=1

# Iterate over Regions and Wave dummies
for (model in 1:length(region_lm_models)) {
  
  # Get model stats
  lm_model = region_lm_models[[model]]
  coefficients <- coef(lm_model)
  coef_names <- names(coef(lm_model))
  
   # Get stats
  coefficients <- coef(lm_model)
  coef_names <- names(coef(lm_model))
  # se <- summary(lm_model)$coefficients[, "Std. Error"] use robust SE's
  se <- sqrt(diag(vcovHC(lm_model)))
  se_named <- rep(NA, length(coef_names))
  se_named[names(se)] <- se
  st_errors <- se_named[coef_names]
  
  # Based on model, decide if urban or all county df
  if (model <=4) {
    county = "all counties"
    df = all_regional_weekly_spatial_metrics}
  else {
    county = "urban counties"
    df = urban_regional_weekly_spatial_metrics}
  
  # Based on model, choose cor_length or local_cor as predictor
  if (model %in% c(1,2,5,6)) {pred = predictor[1]}
  else {pred = predictor[2]}
    
  # Wave dummies not included for even models
  if (model %% 2 == 0) {
    wave = "every wave"
    for (r in 1:length(regions)) {
      region <- regions[r]
      if (r==4) {interaction = 0
      se_total = st_errors[2]}
      else {
      interaction = coefficients[5+r]
      se_total = sqrt(sum((st_errors[5+r])^2 + (st_errors[2])^2))
      }
      # Store coefficient
      full_coef1[j] = save_coefficient(interaction)
    
      # Print interpretation and significance
      significant1[j] <- is_significant(as.numeric(full_coef1[j]), as.numeric((se_total)))
      print_interpretation(full_coef1[j], wave, region, "are disregarded", significant1[j], pred, county, df)}}
  
  # Wave dummies with mhhinc tier dummies
  else {
  # Iterate over each wave    
  for (w in 1:length(waves)) {
    wave <- waves[w]
    # Iterate of each tier difference
    for (r in 1:length(regions)) {
      region <- regions[r]
      if (wave == "wave 1") {
        partial_interaction_w <- 0
        se_partial_w <- 0
      } else {
        partial_interaction_w <- coefficients[(6 + w)]
        se_partial_w <- st_errors[(6 + w)]
      }
      if (region == "West") {
        partial_interaction_r <- 0
        se_partial_r <- 0
      } else {
        partial_interaction_r <- coefficients[(3*r+7)]
        se_partial_r <- st_errors[(3*r+7)]
      } 
      if (region != "West" & wave != "wave 1") {
        full_interaction_wr <- coefficients[paste0(pred,":factor(wave)", w, ":", tolower(region))]
        se_full_wr <- st_errors[paste0(pred,":factor(wave)", w, ":", region)]
      } else {
        full_interaction_wr <- 0
        se_full_wr <- 0
      }
    # Calculate total standard error
    se_total <- sqrt(se_partial_w^2 + se_partial_w^2 + se_full_wr^2 + st_errors[2]^2)
    # Store coefficient information
    interaction <- partial_interaction_w + partial_interaction_r + full_interaction_wm
    
    # Store coefficient
    full_coef[i] = save_coefficient(interaction)
    
    # Print interpretation and significance
    significant[i] <- is_significant(as.numeric(full_coef[i]), as.numeric((se_total)))
    print_interpretation(full_coef[i], wave, region, "are disregarded", significant[i], pred, county, df)
    i <- i + 1
    }}}
}
```

Regional effects are strong in all regions, but weaker in the Northeast. Strongest results are in the West. Significant results across all waves, particularly strong regional effects in wave 1. Effects are not as discernible among Urban counties. Correlation length is better for predicting covid when discerning regional effects.

# Meichen: MHHINC + Wave Models (2 data sets, 8 models, 4 tables, 2 models/table)

## Prepare Model Combinations

```{r}
# Data sets: (1) all counties & (2) urban counties
datasets = list(all_mhhinc_weekly_spatial_metrics, urban_mhhinc_weekly_spatial_metrics)
df_names = c("all","urban")

# Predictor: (1) correlation length & (2) local correlation
predictor = c("cor_lengths", "r_0_50") #unlog local cor
predictor_names = c("corlengths","localcor")

# Covariates (1) mhhinc & (2) mhhinc + wave
covariates = list(c("*factor(wave)*same_tier","*factor(wave)*tier_diff_1","*factor(wave)*tier_diff_2"),
                  c("*same_tier","*tier_diff_1","*tier_diff_2"))
var_names = c("wave_mhhinc","mhhinc")
```

## Generate Models

```{r, warning = FALSE}
# Create an empty list to store the models
mhhinc_lm_models <- list()

# Iterate of every combination of data, predictor, and covariates
for (d in 1:length(datasets)) {
  df = datasets[d][[1]]
  for (p in 1:length(predictor)) {
    for (c in 1:length(covariates)) {
      interactions = c()
      for (i in 1:length(covariates[[c]])) {
        interactions[i] <- paste(predictor[p], covariates[[c]][i])}
     
      # Create the formula
      lm_formula <- as.formula(paste("log(next_week_marginal_cases) ~", paste(unlist(interactions), collapse = " + ")))
      
      # Fit the linear model
      lm_model <- lm(lm_formula, data = df)
      
      # Generate a name for the model object
      model_name <- paste(df_names[d],"_", predictor_names[p], "_", var_names[c], sep = "")
      
      # Save the model to the list
      mhhinc_lm_models[[model_name]] <- lm_model
    }}}
```

```{r}
print(names(mhhinc_lm_models))
```

## View Model Summaries

```{r}
for (m in 1:length(mhhinc_lm_models)){
  print(summary(mhhinc_lm_models[[m]]))
}
```

all_corlengths_wave_mhhinc and urban_corlengths_wave_mhhinc do not have
significant interaction terms, will not make a stargazer table for this
model. Will make 3 stargazer tables, for these pairs of models:
  (1) all_corlengths_mhhinc and urban_corlengths_mhhinc
  (2) all_localcor_wave_mhhinc and urban_localcor_wave_mhhinc
  (3) all_localcor_mhhinc and urban_localcor_mhhinc

```{r, warning = FALSE}
# stargazer table for all_corlengths_mhhinc and urban_corlengths_mhhinc
# (1) is all
# (2) is urban 
stargazer(
  c(mhhinc_lm_models[2], mhhinc_lm_models[6]),
  type = 'text', 
  title = "Regression of Covid Cases on Correlation Length and Mhhinc Tier Difference"
)
```

```{r, warning = FALSE}
# stargazer table for all_localcor_wave_mhhinc and urban_localcor_wave_mhhinc
# (1) is all
# (2) is urban
stargazer(
  c(mhhinc_lm_models[3], mhhinc_lm_models[7]),
  type = 'text', 
  title = "Regression of Covid Cases on Local Correlation,Mhhinc Tier Difference, and Wave"
)
```

```{r, warning = FALSE}
# all_localcor_mhhinc and urban_localcor_mhhinc
# (1) is all
# (2) is urban
stargazer(
  c(mhhinc_lm_models[4], mhhinc_lm_models[8]),
  type = 'text', 
  title = "Regression of Covid Cases on Local Correlation and Mhhinc Tier Difference"
)
```

## Print Results 

Do not print results for all_corlengths_wave_mhhinc and urban_corlengths_wave_mhhinc since there's no significant interaction terms.

First look at the models corlengths_mhhinc. If we look at all counties, the interaction terms for cor_lengths:same_tier and cor_lengths:tier_diff_1 are significant. If we only look at urban counties, no interaction terms are significant. I'll print results for all_corlengths_mhhinc. 

```{r}
# Create function that prints results
print_coefficients <- function(coef_val, tier_diff, tier_descr, cor_length_unit) {
  if (!is.na(coef_val)) {
    coef <- coef_val + coefficients["cor_lengths"]
    cat("- Among all counties where the median household income tiers", tier_descr, "\n")
    cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n\n", sep = "")}}

coefficients <- coef(mhhinc_lm_models[[2]])
tier_diff <- c("same_tier", "tier_diff_1")
tier_descr <- c("are the same", "differ by 1")
cor_length_unit <- 50

# Iterate over tier diff dummies
for (m in tier_diff) {
  coef_val <- coefficients[paste("cor_lengths:", m,sep = "")]
  print_coefficients(coef_val, m, tier_descr[match(m, tier_diff)], cor_length_unit)}
```

Next look at the models localcor_wave_mhhinc. If we look at all counties, only the interaction terms for wave_3:tier_diff_2 and local_corr:wave_3:tier_diff_2 are significant. If we look at urban counties, only the interaction terms for local_corr:wave_3 and local_corr:wave_2:tier_diff_1 are significant. 

```{r}
# print results for significant interaction terms for all counties
coefficients <- coef(mhhinc_lm_models[[3]])

coef_val <- coefficients["log(r_0_50):factor(wave)3:tier_diff_2"]
coef <- coef_val + coefficients["log(r_0_50)"]
cat("- Among all counties in wave 3 where the median household income tiers differ by 2 \n")
cat("a 10 % increase in local correlation corresponds to a ", 
        round(exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")
```

```{r}
# print results for significant interaction terms for urban counties
coefficients <- coef(mhhinc_lm_models[[7]])

coef_val <- coefficients["log(r_0_50):factor(wave)2:tier_diff_1"]
coef <- coef_val + coefficients["log(r_0_50)"]
cat("- Among urban counties in wave 2 where the median household income tiers differ by 1 \n")
cat("a 10 % increase in local correlation corresponds to a ", 
        round(exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")
```

Lastly look at the models localcor_mhhinc. If we look at all counties, all three interaction terms are significant. If we look at urban counties, only the interaction terms for log(r_0_50)s:same_tier and log(r_0_50):tier_diff_1 are significant. 

```{r}
# print results for all counties 
# Create function that prints results
print_coefficients <- function(coef_val, tier_diff, tier_descr) {
  if (!is.na(coef_val)) {
    coef <- coef_val + coefficients["log(r_0_50)"]
    cat("- Among all counties where the median household income tiers", tier_descr, "\n")
    cat("a 10 % increase in local correlation corresponds to a ", 
        round(exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")}}

coefficients <- coef(mhhinc_lm_models[[4]])
tier_diff <- c("same_tier", "tier_diff_1", "tier_diff_2")
tier_descr <- c("are the same", "differ by 1", "differ by 2")

# Iterate over tier diff dummies
for (m in tier_diff) {
  coef_val <- coefficients[paste("log(r_0_50):", m,sep = "")]
  print_coefficients(coef_val, m, tier_descr[match(m, tier_diff)])}
```
```{r}
# print results for all counties 
# Create function that prints results
print_coefficients <- function(coef_val, tier_diff, tier_descr) {
  if (!is.na(coef_val)) {
    coef <- coef_val + coefficients["log(r_0_50)"]
    cat("- Among urban counties where the median household income tiers", tier_descr, "\n")
    cat("a 10 % increase in local correlation corresponds to a ", 
        round((exp(coef * log(1.1))* 100 - 100, 2), "% change in cases in the following week\n\n", sep = "")}}

coefficients <- coef(mhhinc_lm_models[[8]])
tier_diff <- c("same_tier", "tier_diff_1")
tier_descr <- c("are the same", "differ by 1")

# Iterate over tier diff dummies
for (m in tier_diff) {
  coef_val <- coefficients[paste("log(r_0_50):", m,sep = "")]
  print_coefficients(coef_val, m, tier_descr[match(m, tier_diff)])}
```






## new result interpretations for mhhinc + wave models

### Check conditions of Normality of Residuals, Homoskedasticity,Linearity , No Perfect Multicollinearity, Independence of Residuals

```{r}
for (lm_model in mhhinc_lm_models) {
# 1. Linearity Check (Visual Inspection)
plot(residuals(lm_model) ~ fitted(lm_model))

# 2. Independence Check
# Durbin-Watson test
print(durbinWatsonTest(lm_model)[3])

# 3. Homoscedasticity Check
# Breusch-Pagan test for Heteroscedasticity
print(bptest(lm_model)$p.value)

# 4. Normality of Residuals Check (Visual Inspection)
hist(residuals(lm_model), main = "Histogram of Residuals")
}

# 5. No Perfect Multicollinearity Check
# Variance Inflation Factors (VIF)
vif(lm(log(next_week_marginal_cases) ~  cor_lengths + factor(wave) + factor(mhhinc_tier) , data = all_mhhinc_weekly_spatial_metrics))
vif(lm(log(next_week_marginal_cases) ~  cor_lengths + factor(wave) + factor(mhhinc_tier) , data = urban_mhhinc_weekly_spatial_metrics))

# Conditions not passed:
## Heteroskedasticity in all_localcor_mhhinc and urban_localcor_mhhinc
## Non-linearity in urban_localcor_wave_mhhinc, urban_localcor_mhhinc
```

## Print non-NA Significant Results

```{r}
# FUNCTIONS DEFINED IN E's Section

# Initialize values
predictor <- c("cor_lengths","r_0_50")
waves <- c("wave 1","wave 2", "wave 3")
tier_diff <- c("same_tier", "tier_diff_1", "tier_diff_2", "tier_diff_3")
tier_descr <- c("are the same", "differ by 1", "differ by 2", "differ by 3")
full_coef = c()
full_coef1 = c()
significant = c()
significant1 = c()
i=1
j=1

# Iterate over Wave and Tier diff dummies
for (model in 1:length(mhhinc_lm_models)) {
  
  # Get model stats
  lm_model = mhhinc_lm_models[[model]]
  coefficients <- coef(lm_model)
  coef_names <- names(coef(lm_model))
  # se <- summary(lm_model)$coefficients[, "Std. Error"] use robust SE's
  se <- sqrt(diag(vcovHC(lm_model)))
  se_named <- rep(NA, length(coef_names))
  se_named[names(se)] <- se
  st_errors <- se_named[coef_names]
  
  # Based on model, decide if urban or all county df
  if (model <=4) {
    county = "all counties"
    df = all_mhhinc_weekly_spatial_metrics}
  else {
    county = "urban counties"
    df = urban_mhhinc_weekly_spatial_metrics}
  
  # Based on model, choose cor_length or local_cor as predictor
  if (model %in% c(1,2,5,6)) {pred = predictor[1]}
  else {pred = predictor[2]}
    
  # Wave dummies not included for even models
  if (model %% 2 == 0) {
    wave = "every wave"
    for (m in 1:length(tier_diff)) {
      tierdiff <- tier_diff[m]
      if (m==4) {interaction = 0
      se_total = st_errors[2]}
      else {
      interaction = coefficients[5+m]
      se_total = sqrt(sum((st_errors[5+m])^2 + (st_errors[2])^2))
      }
      # Store coefficient
      full_coef1[j] = save_coefficient(interaction)
    
      # Print interpretation and significance
      significant1[j] <- is_significant(as.numeric(full_coef1[j]), as.numeric((se_total)))
      print_interpretation(full_coef1[j], wave, region="whole US", tier_descr[m], significant1[j], pred, county, df)}}
  
  # Wave dummies with mhhinc tier dummies
  else {
  # Iterate over each wave    
  for (w in 1:length(waves)) {
    wave <- waves[w]
    # Iterate of each tier difference
    for (m in 1:length(tier_diff)) {
      tierdiff <- tier_diff[m]
      if (wave == "Wave 1") {
        partial_interaction_w <- 0
        se_partial_w <- 0
      } else {
        partial_interaction_w <- coefficients[(7 + w)]
        se_partial_w <- st_errors[(7 + w)]
      }
      if (tierdiff == "tier_diff_3") {
        partial_interaction_m <- 0
        se_partial_m <- 0
      } else {
        partial_interaction_m <- coefficients[(3*m+7)]
        se_partial_m <- st_errors[(3*m+7)]
      } 
      if (tierdiff != "tier_diff_3" & wave != "Wave 1") {
        full_interaction_wm <- coefficients[paste0(pred,":factor(wave)", w, ":", tierdiff)]
        se_full_wm <- st_errors[paste0(pred,":factor(wave)", w, ":", tierdiff)]
      } else {
        full_interaction_wm <- 0
        se_full_wm <- 0
      }
    # Calculate total standard error
    se_total <- sqrt(se_partial_w^2 + se_partial_w^2 + se_full_wm^2 + st_errors[2]^2)
    # Store coefficient information
    interaction <- partial_interaction_w + partial_interaction_m + full_interaction_wm
    
    # Store coefficient
    full_coef[i] = save_coefficient(interaction)
    
    # Print interpretation and significance
    significant[i] <- is_significant(as.numeric(full_coef[i]), as.numeric((se_total)))
    print_interpretation(full_coef[i], wave, region="whole US", tier_descr[m], significant[i], pred, county, df)
    i <- i + 1
    }}}
}
```

Significant differential effects among "equality level." Spread is greater among counties of similar socioeconomic leve. Strong results across every wave but especially in wave 3. Effects are not as discernible among Urban counties. Both correlation length and local correlation are effective metrics for predicting covid to discern socioeconimic effects.




# \########################################## Old Stuff (Do new stuff above this)

```{r}
# Weekly Spatial Metrics with Poverty Columns
poverty_weekly_spatial_metrics = read.csv("poverty_weekly_spatial_metrics.csv")

# same data set but calculations from urban counties only (pop >250k)
urban_poverty_weekly_spatial_metrics = read.csv("urban_poverty_weekly_spatial_metrics.csv")
```

Output: poverty_weekly_spatial_metrics - Weekly data set with
corresponding covid cases, spatial correlations, and correlation
lengths - 942 rows (weeks 9 - 165 x 6 poverty tiers) x 61 columns (date,
cases, cor length, C(r), poverty dummies) - features: start date of
week, total cases, marginal cases, next week's marginal cases, C(r) for
distance intervals from [0,50] to [970,1000], correlation length, pov
tier (1,1) dummy, pov tier (2,2) dummy, pov tier (3,3) dummy, pov tier
(1,2) dummy, pov tier (1,3) dummy, pov tier (2,3) dummy

## Model on entire data

```{r}
# Log-Linear Model (better)
plot(weekly_spatial_metrics_waves$cor_lengths,log(weekly_spatial_metrics_waves$next_week_marginal_cases))
plot(weekly_spatial_metrics_waves$r_0_50,log(weekly_spatial_metrics_waves$next_week_marginal_cases))

plot(weekly_spatial_metrics_waves$r_0_50,weekly_spatial_metrics_waves$next_week_marginal_cases)

# Log-Log Model (bad)
plot(log(weekly_spatial_metrics_waves$cor_lengths),log(weekly_spatial_metrics_waves$next_week_marginal_cases))
plot(log(weekly_spatial_metrics_waves$r_0_50),log(weekly_spatial_metrics_waves$next_week_marginal_cases))
```

```{r}
# Regress next week's marginal cases on correlation length
simple_model <- lm(log(weekly_spatial_metrics_waves$next_week_marginal_cases) ~ weekly_spatial_metrics_waves$cor_lengths, data = weekly_spatial_metrics_waves)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(simple_model, type = "HC1")))
robust_test <- coeftest(simple_model, vcov = vcovHC(simple_model, type = "HC1"))
print(robust_test)

# Regress next week's marginal cases on local correlation
simple_model2 <- lm(log(weekly_spatial_metrics_waves$next_week_marginal_cases) ~ weekly_spatial_metrics_waves$r_0_50, data = weekly_spatial_metrics_waves)
robust_se <- sqrt(diag(vcovHC(simple_model2, type = "HC1")))
robust_test <- coeftest(simple_model2, vcov = vcovHC(simple_model2, type = "HC1"))
print(robust_test)


# Print Result
paste("a 1 sd increase in correlation length (",cor_length_unit, " km) corresponds to a ", round(simple_model$coefficients[2]*cor_length_unit*100,2),"% change in cases in the following week", sep="")
local_cor_unit = round(sd(weekly_spatial_metrics_waves$r_0_50),2)
paste("a 1 sd increase in local correlation (",local_cor_unit, ") corresponds to a ", round(simple_model2$coefficients[2]*local_cor_unit*100,2),"% change in cases in the following week", sep="")
```

```{r}
# For Urban counties
urban_model <- lm(log(urban_weekly_spatial_metrics_waves$next_week_marginal_cases) ~ urban_weekly_spatial_metrics_waves$cor_lengths, data = urban_weekly_spatial_metrics_waves)
robust_se <- sqrt(diag(vcovHC(urban_model, type = "HC1")))
robust_test <- coeftest(urban_model, vcov = vcovHC(urban_model, type = "HC1"))
print(robust_test)

urban_model <- lm(log(urban_weekly_spatial_metrics_waves$next_week_marginal_cases) ~ r_0_50, data = urban_weekly_spatial_metrics_waves)
robust_se <- sqrt(diag(vcovHC(urban_model, type = "HC1")))
robust_test <- coeftest(urban_model, vcov = vcovHC(urban_model, type = "HC1"))
print(robust_test)

# Print Result
cor_length_unit = 1
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round(urban_model$coefficients[2]*cor_length_unit*100,2),"% change in cases in the following week among urban counties")
cor_length_unit = 50
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round(urban_model$coefficients[2]*cor_length_unit*100,2),"% change in cases in the following week among urban counties")
local_cor_unit = 10
paste("a",local_cor_unit, "% increase in correlation length corresponds to a ", round(exp(urban_model$coefficients[2]*cor_length_unit*log(1.1)*100-100,2),"% change in cases in the following week among urban counties")
```

## Model based on median household income

```{r}
# log-linear model
# mhhinc tier difference dummies, urban counties
urban_model <- lm(log(next_week_marginal_cases) ~ cor_lengths +
                        same_tier + tier_diff_1 + tier_diff_2 +same_tier*cor_lengths +
                          tier_diff_1*cor_lengths +tier_diff_2*cor_lengths, 
                     data = urban_mhhinc_weekly_spatial_metrics)
robust_se <- sqrt(diag(vcovHC(urban_model, type = "HC1")))
robust_test <- coeftest(urban_model, vcov = vcovHC(urban_model, type = "HC1"))
print(robust_test)

cor_length_unit = 50
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round((urban_model$coef[2] + urban_model$coef[6])*cor_length_unit*100,2),"% change in cases in the following week among urban counties in the same tier of mhhinc")
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round((urban_model$coef[2] + urban_model$coef[7])*cor_length_unit*100,2),"% change in cases in the following week between urban counties of mhhinc tiers that differ by 1")
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round((urban_model$coef[2] + urban_model$coef[8])*cor_length_unit*100,2),"% change in cases in the following week between urban counties of mhhinc tiers that differ by 2")
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round(urban_model$coef[2]*cor_length_unit*100,2),"% change in cases in the following week between urban counties of tier 1 and tier 4 (diff 3)")
```

```{r}
# map factor levels to tier levels 
values <- c(1, 2, 3, 4, 6, 7, 8, 11, 12, 16)
tiers <- c("tier_1_1", "tier_1_2", "tier_1_3", "tier_1_4",
           "tier_2_2", "tier_2_3", "tier_2_4",
           "tier_3_3", "tier_3_4",
           "tier_4_4")
mhhinc_factor_tiers <- tibble(Factor = values, Tier = tiers)
print(mhhinc_factor_tiers)
```

```{r}
# full model 
full_mhhinc_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) +
                        factor(mhhinc_tier), 
                     data = mhhinc_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(full_mhhinc_model, type = "HC1")))

robust_test <- coeftest(full_mhhinc_model, vcov = vcovHC(full_mhhinc_model, type = "HC1"))
print(robust_test)
```

```{r}
# full model with interaction terms 
full_mhhinc_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) *
                        factor(mhhinc_tier), 
                     data = mhhinc_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(full_mhhinc_model, type = "HC1")))

robust_test <- coeftest(full_mhhinc_model, vcov = vcovHC(full_mhhinc_model, type = "HC1"))
print(robust_test)
```

```{r}
# split into "simple model" for subsetted data 

for(i in 1:nrow(mhhinc_factor_tiers)) {
  # Dynamic filtering based on tier
  tier_value <- mhhinc_factor_tiers$Tier[i]
  #filter_condition <- paste0(tier_value, " == 1")
  mhhinc_weekly_spatial_metrics_subset <- mhhinc_weekly_spatial_metrics %>%
    filter(!!rlang::sym(tier_value) == 1)
  
  # Linear model
  mhhinc_simple_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                           data = mhhinc_weekly_spatial_metrics_subset)
  
  # Perform hypothesis tests with robust standard errors for heteroskedasticity
  robust_se <- sqrt(diag(vcovHC(mhhinc_simple_model, type = "HC1")))
  
  robust_test <- coeftest(mhhinc_simple_model, vcov = vcovHC(mhhinc_simple_model, type = "HC1"))
  print(robust_test)
  # Print result
  result <- paste("A 10% increase in correlation length corresponds to a ", 
                  round(exp(mhhinc_simple_model$coefficients[2] * log(1.1))* 100 - 100,2),
                  "% change in cases in the following week for counties in ", tier_value, "mhhinc.")
  print(result)
}
```

## Model based on poverty tiers

```{r}
# full model 
full_pov_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + 
                       tier_11 + tier_22 + tier_33 +tier_12 + tier_13, 
                     data = poverty_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(full_pov_model, type = "HC1")))

robust_test <- coeftest(full_pov_model, vcov = vcovHC(full_pov_model, type = "HC1"))
print(robust_test)
```

```{r}
# full model with interaction terms 
full_pov_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + 
                       tier_11  + tier_22 + tier_33 + tier_12 + tier_13 + 
                       log(cor_lengths) * tier_11 + log(cor_lengths) * tier_22 + log(cor_lengths) * tier_33 
                     + log(cor_lengths) * tier_12 + log(cor_lengths) * tier_13, 
                     data = poverty_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(full_pov_model, type = "HC1")))

robust_test <- coeftest(full_pov_model, vcov = vcovHC(full_pov_model, type = "HC1"))
print(robust_test)
```

```{r}
# split into a "simple model" for subsetted data 

# vector of tier names
pov_tiers <- c("tier_11", "tier_22", "tier_33", "tier_12", "tier_13", "tier_23")
for(tier_value in pov_tiers) {
  # Dynamic filtering based on the current tier in the loop
  pov_weekly_spatial_metrics_subset <- poverty_weekly_spatial_metrics %>%
    filter(!!rlang::sym(tier_value) == 1)
  
  # Linear model
  pov_simple_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                            data = pov_weekly_spatial_metrics_subset)
  
  # Perform hypothesis tests with robust standard errors for heteroskedasticity
  robust_test <- coeftest(pov_simple_model, vcov = vcovHC(pov_simple_model, type = "HC1"))
  print(robust_test)
  
  # Print result
  result <- paste("A 10% increase in correlation length corresponds to a ", 
                  round(exp(pov_simple_model$coefficients[2]* log(1.1))* 100 - 100,2),
                  "% change in cases in the following week for counties in ", tier_value, "for poverty.")
  print(result)
}

```

## Model based on regions

```{r}
# full model without interactions
region_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + northeast + midwest + south, data = regional_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(region_model, type = "HC1")))

robust_test <- coeftest(region_model, vcov = vcovHC(region_model, type = "HC1"))
print(robust_test)

# full model with interactions
region_model_int <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + northeast + northeast*log(cor_lengths) + midwest + midwest*log(cor_lengths) + south + south*log(cor_lengths), data = regional_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se_int <- sqrt(diag(vcovHC(region_model_int, type = "HC1")))

robust_test_int <- coeftest(region_model_int, vcov = vcovHC(region_model_int, type = "HC1"))
print(robust_test_int)
```

## Split into a "simple model" for subsetted data

```{r}
# simple model for northeast
ne_weekly_spatial_metrics <- regional_weekly_spatial_metrics %>% filter(northeast == 1)

northeast_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                         data = ne_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(northeast_model, type = "HC1")))

robust_test <- coeftest(northeast_model, vcov = vcovHC(northeast_model, type = "HC1"))
print(robust_test)
# Print Result
paste("a 10% increase in correlation length in the Northeast region corresponds to a ", round(exp(northeast_model$coefficients[2]* log(1.1))* 100 - 100,2),"% change in cases in the following week")
```

```{r}
# simple model for midwest
mw_weekly_spatial_metrics <- regional_weekly_spatial_metrics %>% filter(midwest == 1)

midwest_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                         data = mw_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(midwest_model, type = "HC1")))

robust_test <- coeftest(midwest_model, vcov = vcovHC(midwest_model, type = "HC1"))
print(robust_test)
# Print Result
paste("a 10% increase in correlation length in the MidWest region corresponds to a ", round(exp(midwest_model$coefficients[2]* log(1.1))* 100 - 100,2),"% change in cases in the following week")
```

```{r}
# simple model for south
s_weekly_spatial_metrics <- regional_weekly_spatial_metrics %>% filter(south == 1)

south_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                         data = s_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(south_model, type = "HC1")))

robust_test <- coeftest(south_model, vcov = vcovHC(south_model, type = "HC1"))
print(robust_test)
# Print Result
paste("a 10% increase in correlation length in the South region corresponds to a ", round(exp(south_model$coefficients[2]* log(1.1))* 100 - 100,2),"% change in cases in the following week")
```

```{r}
# simple model for west
w_weekly_spatial_metrics <- regional_weekly_spatial_metrics %>% filter(region == 'West')

west_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                         data = w_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(west_model, type = "HC1")))

robust_test <- coeftest(west_model, vcov = vcovHC(west_model, type = "HC1"))
print(robust_test)
# Print Result
paste("a 10% increase in correlation length in the West region corresponds to a ", round(exp(west_model$coefficients[2]* log(1.1))* 100 - 100,2),"% change in cases in the following week")
```

## Model based on time waves

```{r}
# Full Wave Model (w dummy variables)
full_wave_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + wave_1 + wave_2, data = weekly_spatial_metrics_waves)

robust_se <- sqrt(diag(vcovHC(full_wave_model, type = "HC1")))

robust_test <- coeftest(full_wave_model, vcov = vcovHC(full_wave_model, type = "HC1"))
print(robust_test)
```

```{r}
# Wave 1 Simple Model (weeks 9-47: 2020-03-28 - 2020-12-19)
wave1_data <- weekly_spatial_metrics_waves %>% filter(X >= 1 & X <= 39)

wave1_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), data = wave1_data)

# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(wave1_model, type = "HC1")))

robust_test <- coeftest(wave1_model, vcov = vcovHC(wave1_model, type = "HC1"))
print(robust_test)

paste("a 10% increase in correlation length corresponds to a ", round(exp(wave1_model$coefficients[2]* log(1.1))* 100 - 100,2),"% change in cases in the following week")
```

```{r}
# Wave 2 Simple Model (weeks 48-97: 2020-12-26 - 2021-12-04)
wave2_data <- weekly_spatial_metrics_waves %>% filter(X >= 40 & X <= 89)

wave2_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), data = wave2_data)

# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(wave2_model, type = "HC1")))

robust_test <- coeftest(wave2_model, vcov = vcovHC(wave2_model, type = "HC1"))
print(robust_test)

paste("a 10% increase in correlation length corresponds to a ", round(exp(wave2_model$coefficients[2]*log(1.1))* 100 - 100,2),"% change in cases in the following week")
```

```{r}
# Wave 3 Simple model (weeks 98-160: 2021-12-11 - 2023-03-25)
wave3_data <- weekly_spatial_metrics_waves %>% filter(X >= 90 & X <= 157)  

wave3_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), data = wave3_data)

# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(wave3_model, type = "HC1")))

robust_test <- coeftest(wave3_model, vcov = vcovHC(wave3_model, type = "HC1"))
print(robust_test)

paste("a 10% increase in correlation length corresponds to a ", round(exp(wave3_model$coefficients[2]*log(1.1))*100-100),2),"% change in cases in the following week")
```
