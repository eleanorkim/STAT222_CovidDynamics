---
title: "Spatial Dynamics - Modeling"
subtitle: "Aarushi Somani, Eleanor Kim, Lauren Murai, Meichen Chen"
output:
  pdf_document: default
  html_document: default
date: '2024-03-11'
---

```{r}
#load packages
library(sandwich)
library(lmtest)
library(dplyr)
library(tibble)
library(stargazer)
```

# Read in 7 Datasets

## All county data + Urban county data with Wave dummies

```{r}
# Weekly Spatial Metrics with Time Wave Columns
all_weekly_spatial_metrics_waves = read.csv("weekly_spatial_metrics_waves.csv")

# same data set but calculations from urban counties only (pop >250k)
urban_weekly_spatial_metrics_waves = read.csv("urban_weekly_spatial_metrics_waves.csv")
```
Output: weekly_spatial_metrics_waves
  - Weekly data set with corresponding covid cases, spatial correlations, and correlation lengths
  - 157 rows (weeks 9 - 165) x 57 columns (date, cases, cor length, C(r), wave dummies)
  - features: start date of week, total cases, marginal cases, next week's marginal cases, C(r) for distance intervals from [0,50] to [970,1000], correlation length, wave, wave 1 dummy, wave 2 dummy

## All county data + Urban county data with Region + Wave dummies

```{r}
# Weekly Spatial Metrics with Region Columns
all_regional_weekly_spatial_metrics = read.csv("regional_weekly_spatial_metrics.csv")

# same data set but calculations from urban counties only (pop >250k)
urban_regional_weekly_spatial_metrics = read.csv("urban_regional_weekly_spatial_metrics.csv")
```
Output: regional_weekly_spatial_metrics
  - Weekly data set with corresponding covid cases, spatial correlations, and correlation lengths
  - 628 rows (weeks 9 - 165 x 4 regions) x 59 columns (date, cases, cor length, C(r), region dummies)
  - features: start date of week, total cases, marginal cases, next week's marginal cases, C(r) for distance intervals from [0,50] to [970,1000], correlation length, region, northeast dummy, midwest dummy, south dummy

## All county data + Urban county data with MHHINC + Wave dummies

```{r}
# Weekly Spatial Metrics with Median Household Income Columns
all_mhhinc_weekly_spatial_metrics = read.csv("mhhinc_weekly_spatial_metrics.csv")

# same data set but calculations from urban counties only (pop >250k)
urban_mhhinc_weekly_spatial_metrics = read.csv("urban_mhhinc_weekly_spatial_metrics.csv")
```
Output: mhhinc_weekly_spatial_metrics
  - Weekly data set with corresponding covid cases, spatial correlations, and correlation lengths
  - 1570 rows (weeks 9 - 165 x 10 combinations of 4 tiers) x 71 columns (date, cases, cor length, C(r), poverty dummies)
  - features: start date of week, total cases, marginal cases, next week's marginal cases, C(r) for distance intervals from [0,50] to [970,1000], correlation length, income pair tiers  (4 choose 2) dummies, income tier differences (same tier, difference of 1, difference of 2, difference of 3)

## All county data with Region + MHHINC + Wave dummies

```{r}
# Weekly Spatial Metrics with Median Household Income Columns
all_region_mhhinc_weekly_spatial_metrics = read.csv("region_mhhinc_weekly_spatial_metrics.csv")
```
Output: region_mhhinc_weekly_spatial_metrics
  - Weekly data set with corresponding covid cases, spatial correlations, and correlation lengths
  - 6280 rows (weeks 9 - 165 x 10 combinations of 4 tiers X 4 regions) x 67 columns (date, cases, cor length, C(r), region and tier difference dummies)
  - features: start date of week, total cases, marginal cases, next week's marginal cases, C(r) for distance intervals from [0,50] to [970,1000], correlation length, region dummies, tier difference (same,1,2,3) dummies
  
# Eleanor: Region + Median Household Income Models (1 data set, 2 models, 1 table, 1 model/table)

## Prepare Model Combinations
```{r}
# Predictor: (1) correlation length & (2) log(local correlation)
predictor = c("cor_lengths", "log(r_0_50)")
pred_names = c("corlength","localcor")

# Covariates (1) region + mhhinc & (2) region + mhhinc + wave
covariates = list(c("*factor(region)*same_tier","*factor(region)*tier_diff_1","*factor(region)*tier_diff_2"))
var_names = c("region_mhhinc")
```

## Generate Models
```{r}
# Create an empty list to store the models
lm_models <- list()

# Iterate over every combination of data, predictor, and covariates
for (p in 1:length(predictor)) {
  for (c in 1:length(covariates)) {
    interactions = c()
    for (i in 1:length(covariates[[c]])) {
      interactions[i] <- paste(predictor[p], covariates[[c]][i]) }
    
    # Create the formula & fit linear model
    lm_formula <- as.formula(paste("log(next_week_marginal_cases) ~", paste(unlist(interactions), collapse = " + ")))
    lm_model <- lm(lm_formula, data = all_region_mhhinc_weekly_spatial_metrics)
    
    # Name model and save to list
    model_name <- paste("all_", pred_names[p], "_", var_names[c], sep = "")
    lm_models[[model_name]] <- lm_model}}
```

# View Model Summaries
```{r}
for (m in 1:length(lm_models)){
  print(summary(lm_models[[m]]))
}
```

Seems like we only have significant interaction terms in the first model with correlation length

# Create Table
```{r}
# Correlation Length Models
stargazer(
  lm_models[1:2],
  type = 'text'
)

## note: the two columns here are the difference predictors, not different data (no urban county df)
```

# Print Results
```{r}
# Create function that prints results
print_coefficients <- function(coef_val, region, tier_diff, tier_descr, cor_length_unit) {
  if (!is.na(coef_val)) {
    coef <- coef_val + coefficients["cor_lengths"]
    cat("- Among counties in the", region, "where the median household income tiers", tier_descr, "\n")
    cat("a ", cor_length_unit, " km increase in correlation length corresponds to a ", 
        round(coef * cor_length_unit * 100, 2), "% change in cases in the following week\n", sep = "")}}

coefficients <- coef(lm_models[[1]])
regions <- c("Northeast", "West", "South")
tier_diff <- c("same_tier", "tier_diff_1", "tier_diff_2")
tier_descr <- c("are the same", "differ by 1", "differ by 2")
cor_length_unit <- 50

# Iterate over Regions and Tier diff dummies
for (r in regions) {
  for (m in tier_diff) {
    coef_val <- coefficients[paste("cor_lengths:factor(region)", r, ":", m, sep = "")]
    print_coefficients(coef_val, r, m, tier_descr[match(m, tier_diff)], cor_length_unit)}}

# Midwest Coefficients
for (m in tier_diff) {
  coef_val <- coefficients[paste("cor_lengths:", m, sep = "")]
  print_coefficients(coef_val, "Midwest", m, tier_descr[match(m, tier_diff)], cor_length_unit)}

# Tier diff 3 counties
for (r in regions) {
  coef_val <- coefficients[paste("cor_lengths:factor(region)", r, sep = "")]
  print_coefficients(coef_val, r, "tier_diff_3", "differ by 3", cor_length_unit)}

# Midwest & Tier diff 3
coef_val <- coefficients["cor_lengths"]
print_coefficients(coef_val, "Midwest", "tier_diff_3", "differ by 3", cor_length_unit)

```
Results we can report:
Among counties in the **South** where the median household income **tiers are the same**
a 50 km increase in correlation length corresponds to a *126.96%* change in cases in the following week
Among counties in the **Midwest** where the median household income **tiers differ by 1**
a 50 km increase in correlation length corresponds to a *118.23%* change in cases in the following week



# Lauren: General + Wave Models (2 data sets, 8 models, 2 tables, 2 models/table)

# Aarushi: Region + Wave Models (2 data sets, 8 models, 2 tables, 2 models/table)


# Meichen: MHHINC + Wave Models (2 data sets, 8 models, 2 tables, 2 models/table)

## Prepare Model Combinations
```{r}
# Data sets: (1) all counties & (2) urban counties
datasets = list(all_mhhinc_weekly_spatial_metrics,urban_mhhinc_weekly_spatial_metrics)
df_names = c("all","urban")

# Predictor: (1) correlation length & (2) log(local correlation)
predictor = c("cor_lengths", "log(r_0_50)")
predictor_names = c("corlengths","localcor")

# Covariates (1) region + mhhinc & (2) region + mhhinc + wave
covariates = list(c("*factor(wave)*same_tier","*factor(wave)*tier_diff_1","*factor(wave)*tier_diff_2"),
                  c("*same_tier","*tier_diff_1","*tier_diff_2"))
var_names = c("wave_mhhinc","mhhinc")
```

## Generate Models
```{r}
# Create an empty list to store the models
lm_models <- list()

# Iterate of every combination of data, predictor, and covariates
for (d in 1:length(datasets)) {
  df = datasets[d][[1]]
  for (p in 1:length(predictor)) {
    for (c in 1:length(covariates)) {
      for (i in 1:length(covariates[[c]])) {
        interactions[i] <- paste(predictor[p], covariates[[c]][i])}
     
      # Create the formula
      lm_formula <- as.formula(paste("log(next_week_marginal_cases) ~", paste(unlist(interactions), collapse = " + ")))
      
      # Fit the linear model
      lm_model <- lm(lm_formula, data = df)
      
      # Generate a name for the model object
      model_name <- paste(df_names[d],"_", predictor_names[p], "_", var_names[c], sep = "")
      
      # Save the model to the list
      lm_models[[model_name]] <- lm_model
    }}}
```

## View Model Summaries
```{r}
for (m in 1:length(lm_models)){
  print(summary(lm_models[[m]]))
}
```






############################################ Old Stuff (Do new stuff above this)

```{r}
# Weekly Spatial Metrics with Poverty Columns
poverty_weekly_spatial_metrics = read.csv("poverty_weekly_spatial_metrics.csv")

# same data set but calculations from urban counties only (pop >250k)
urban_poverty_weekly_spatial_metrics = read.csv("urban_poverty_weekly_spatial_metrics.csv")
```
Output: poverty_weekly_spatial_metrics
  - Weekly data set with corresponding covid cases, spatial correlations, and correlation lengths
  - 942 rows (weeks 9 - 165 x 6 poverty tiers) x 61 columns (date, cases, cor length, C(r), poverty dummies)
  - features: start date of week, total cases, marginal cases, next week's marginal cases, C(r) for distance intervals from [0,50] to [970,1000], correlation length, pov tier (1,1) dummy, pov tier (2,2) dummy, pov tier (3,3) dummy, pov tier (1,2) dummy, pov tier (1,3) dummy, pov tier (2,3) dummy
  
  
# Model on entire data


```{r}
# Log-Linear Model (better)
plot(weekly_spatial_metrics_waves$cor_lengths,log(weekly_spatial_metrics_waves$next_week_marginal_cases))

# Log-Log Model (bad)
plot(log(weekly_spatial_metrics_waves$cor_lengths),log(weekly_spatial_metrics_waves$next_week_marginal_cases))
```

```{r}
# Regress next week's marginal cases on correlation length
simple_model <- lm(log(weekly_spatial_metrics_waves$next_week_marginal_cases) ~ weekly_spatial_metrics_waves$cor_lengths, data = weekly_spatial_metrics_waves)

# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(simple_model, type = "HC1")))

robust_test <- coeftest(simple_model, vcov = vcovHC(simple_model, type = "HC1"))
print(robust_test)

# Print Result
cor_length_unit = 1
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round(simple_model$coefficients[2]*cor_length_unit*100,2),"% change in cases in the following week")
cor_length_unit = 50
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round(simple_model$coefficients[2]*cor_length_unit*100,2),"% change in cases in the following week")
```

```{r}
# For Urban counties
urban_model <- lm(log(urban_weekly_spatial_metrics_waves$next_week_marginal_cases) ~ urban_weekly_spatial_metrics_waves$cor_lengths, data = urban_weekly_spatial_metrics_waves)
robust_se <- sqrt(diag(vcovHC(urban_model, type = "HC1")))
robust_test <- coeftest(urban_model, vcov = vcovHC(urban_model, type = "HC1"))
print(robust_test)

# Print Result
cor_length_unit = 1
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round(urban_model$coefficients[2]*cor_length_unit*100,2),"% change in cases in the following week among urban counties")
cor_length_unit = 50
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round(urban_model$coefficients[2]*cor_length_unit*100,2),"% change in cases in the following week among urban counties")
```

# Model based on median household income

```{r}
# log-linear model
# mhhinc tier difference dummies, urban counties
urban_model <- lm(log(next_week_marginal_cases) ~ cor_lengths +
                        same_tier + tier_diff_1 + tier_diff_2 +same_tier*cor_lengths +
                          tier_diff_1*cor_lengths +tier_diff_2*cor_lengths, 
                     data = urban_mhhinc_weekly_spatial_metrics)
robust_se <- sqrt(diag(vcovHC(urban_model, type = "HC1")))
robust_test <- coeftest(urban_model, vcov = vcovHC(urban_model, type = "HC1"))
print(robust_test)

cor_length_unit = 50
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round((urban_model$coef[2] + urban_model$coef[6])*cor_length_unit*100,2),"% change in cases in the following week among urban counties in the same tier of mhhinc")
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round((urban_model$coef[2] + urban_model$coef[7])*cor_length_unit*100,2),"% change in cases in the following week between urban counties of mhhinc tiers that differ by 1")
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round((urban_model$coef[2] + urban_model$coef[8])*cor_length_unit*100,2),"% change in cases in the following week between urban counties of mhhinc tiers that differ by 2")
paste("a",cor_length_unit, "km increase in correlation length corresponds to a ", round(urban_model$coef[2]*cor_length_unit*100,2),"% change in cases in the following week between urban counties of tier 1 and tier 4 (diff 3)")
```

```{r}
# map factor levels to tier levels 
values <- c(1, 2, 3, 4, 6, 7, 8, 11, 12, 16)
tiers <- c("tier_1_1", "tier_1_2", "tier_1_3", "tier_1_4",
           "tier_2_2", "tier_2_3", "tier_2_4",
           "tier_3_3", "tier_3_4",
           "tier_4_4")
mhhinc_factor_tiers <- tibble(Factor = values, Tier = tiers)
print(mhhinc_factor_tiers)
```

```{r}
# full model 
full_mhhinc_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) +
                        factor(mhhinc_tier), 
                     data = mhhinc_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(full_mhhinc_model, type = "HC1")))

robust_test <- coeftest(full_mhhinc_model, vcov = vcovHC(full_mhhinc_model, type = "HC1"))
print(robust_test)
```

```{r}
# full model with interaction terms 
full_mhhinc_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) *
                        factor(mhhinc_tier), 
                     data = mhhinc_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(full_mhhinc_model, type = "HC1")))

robust_test <- coeftest(full_mhhinc_model, vcov = vcovHC(full_mhhinc_model, type = "HC1"))
print(robust_test)
```

```{r}
# split into "simple model" for subsetted data 

for(i in 1:nrow(mhhinc_factor_tiers)) {
  # Dynamic filtering based on tier
  tier_value <- mhhinc_factor_tiers$Tier[i]
  #filter_condition <- paste0(tier_value, " == 1")
  mhhinc_weekly_spatial_metrics_subset <- mhhinc_weekly_spatial_metrics %>%
    filter(!!rlang::sym(tier_value) == 1)
  
  # Linear model
  mhhinc_simple_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                           data = mhhinc_weekly_spatial_metrics_subset)
  
  # Perform hypothesis tests with robust standard errors for heteroskedasticity
  robust_se <- sqrt(diag(vcovHC(mhhinc_simple_model, type = "HC1")))
  
  robust_test <- coeftest(mhhinc_simple_model, vcov = vcovHC(mhhinc_simple_model, type = "HC1"))
  print(robust_test)
  # Print result
  result <- paste("A 10% increase in correlation length corresponds to a ", 
                  round(mhhinc_simple_model$coefficients[2]*10,2),
                  "% change in cases in the following week for counties in ", tier_value, "mhhinc.")
  print(result)
}
```

# Model based on poverty tiers  

```{r}
# full model 
full_pov_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + 
                       tier_11 + tier_22 + tier_33 +tier_12 + tier_13, 
                     data = poverty_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(full_pov_model, type = "HC1")))

robust_test <- coeftest(full_pov_model, vcov = vcovHC(full_pov_model, type = "HC1"))
print(robust_test)
```

```{r}
# full model with interaction terms 
full_pov_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + 
                       tier_11  + tier_22 + tier_33 + tier_12 + tier_13 + 
                       log(cor_lengths) * tier_11 + log(cor_lengths) * tier_22 + log(cor_lengths) * tier_33 
                     + log(cor_lengths) * tier_12 + log(cor_lengths) * tier_13, 
                     data = poverty_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(full_pov_model, type = "HC1")))

robust_test <- coeftest(full_pov_model, vcov = vcovHC(full_pov_model, type = "HC1"))
print(robust_test)
```

```{r}
# split into a "simple model" for subsetted data 

# vector of tier names
pov_tiers <- c("tier_11", "tier_22", "tier_33", "tier_12", "tier_13", "tier_23")
for(tier_value in pov_tiers) {
  # Dynamic filtering based on the current tier in the loop
  pov_weekly_spatial_metrics_subset <- poverty_weekly_spatial_metrics %>%
    filter(!!rlang::sym(tier_value) == 1)
  
  # Linear model
  pov_simple_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                            data = pov_weekly_spatial_metrics_subset)
  
  # Perform hypothesis tests with robust standard errors for heteroskedasticity
  robust_test <- coeftest(pov_simple_model, vcov = vcovHC(pov_simple_model, type = "HC1"))
  print(robust_test)
  
  # Print result
  result <- paste("A 10% increase in correlation length corresponds to a ", 
                  round(pov_simple_model$coefficients[2]*10,2),
                  "% change in cases in the following week for counties in ", tier_value, "for poverty.")
  print(result)
}

```

# Model based on regions

```{r}
# full model without interactions
region_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + northeast + midwest + south, data = regional_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(region_model, type = "HC1")))

robust_test <- coeftest(region_model, vcov = vcovHC(region_model, type = "HC1"))
print(robust_test)

# full model with interactions
region_model_int <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + northeast + northeast*log(cor_lengths) + midwest + midwest*log(cor_lengths) + south + south*log(cor_lengths), data = regional_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se_int <- sqrt(diag(vcovHC(region_model_int, type = "HC1")))

robust_test_int <- coeftest(region_model_int, vcov = vcovHC(region_model_int, type = "HC1"))
print(robust_test_int)
```
# Split into a "simple model" for subsetted data 

```{r}
# simple model for northeast
ne_weekly_spatial_metrics <- regional_weekly_spatial_metrics %>% filter(northeast == 1)

northeast_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                         data = ne_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(northeast_model, type = "HC1")))

robust_test <- coeftest(northeast_model, vcov = vcovHC(northeast_model, type = "HC1"))
print(robust_test)
# Print Result
paste("a 10% increase in correlation length in the Northeast region corresponds to a ", round(northeast_model$coefficients[2]*10,2),"% change in cases in the following week")
```
```{r}
# simple model for midwest
mw_weekly_spatial_metrics <- regional_weekly_spatial_metrics %>% filter(midwest == 1)

midwest_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                         data = mw_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(midwest_model, type = "HC1")))

robust_test <- coeftest(midwest_model, vcov = vcovHC(midwest_model, type = "HC1"))
print(robust_test)
# Print Result
paste("a 10% increase in correlation length in the MidWest region corresponds to a ", round(midwest_model$coefficients[2]*10,2),"% change in cases in the following week")
```

```{r}
# simple model for south
s_weekly_spatial_metrics <- regional_weekly_spatial_metrics %>% filter(south == 1)

south_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                         data = s_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(south_model, type = "HC1")))

robust_test <- coeftest(south_model, vcov = vcovHC(south_model, type = "HC1"))
print(robust_test)
# Print Result
paste("a 10% increase in correlation length in the South region corresponds to a ", round(south_model$coefficients[2]*10,2),"% change in cases in the following week")
```

```{r}
# simple model for west
w_weekly_spatial_metrics <- regional_weekly_spatial_metrics %>% filter(region == 'West')

west_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), 
                         data = w_weekly_spatial_metrics)
# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(west_model, type = "HC1")))

robust_test <- coeftest(west_model, vcov = vcovHC(west_model, type = "HC1"))
print(robust_test)
# Print Result
paste("a 10% increase in correlation length in the West region corresponds to a ", round(west_model$coefficients[2]*10,2),"% change in cases in the following week")
```

# Model based on time waves

```{r}
# Full Wave Model (w dummy variables)
full_wave_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths) + wave_1 + wave_2, data = weekly_spatial_metrics_waves)

robust_se <- sqrt(diag(vcovHC(full_wave_model, type = "HC1")))

robust_test <- coeftest(full_wave_model, vcov = vcovHC(full_wave_model, type = "HC1"))
print(robust_test)
```

```{r}
# Wave 1 Simple Model (weeks 9-47: 2020-03-28 - 2020-12-19)
wave1_data <- weekly_spatial_metrics_waves %>% filter(X >= 1 & X <= 39)

wave1_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), data = wave1_data)

# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(wave1_model, type = "HC1")))

robust_test <- coeftest(wave1_model, vcov = vcovHC(wave1_model, type = "HC1"))
print(robust_test)

paste("a 10% increase in correlation length corresponds to a ", round(wave1_model$coefficients[2]*10,2),"% change in cases in the following week")
```

```{r}
# Wave 2 Simple Model (weeks 48-97: 2020-12-26 - 2021-12-04)
wave2_data <- weekly_spatial_metrics_waves %>% filter(X >= 40 & X <= 89)

wave2_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), data = wave2_data)

# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(wave2_model, type = "HC1")))

robust_test <- coeftest(wave2_model, vcov = vcovHC(wave2_model, type = "HC1"))
print(robust_test)

paste("a 10% increase in correlation length corresponds to a ", round(wave2_model$coefficients[2]*10,2),"% change in cases in the following week")
```

```{r}
# Wave 3 Simple model (weeks 98-160: 2021-12-11 - 2023-03-25)
wave3_data <- weekly_spatial_metrics_waves %>% filter(X >= 90 & X <= 157)  

wave3_model <- lm(log(next_week_marginal_cases) ~ log(cor_lengths), data = wave3_data)

# Perform hypothesis tests with robust standard errors for heteroskedasticity
robust_se <- sqrt(diag(vcovHC(wave3_model, type = "HC1")))

robust_test <- coeftest(wave3_model, vcov = vcovHC(wave3_model, type = "HC1"))
print(robust_test)

paste("a 10% increase in correlation length corresponds to a ", round(wave3_model$coefficients[2]*10,2),"% change in cases in the following week")
```
